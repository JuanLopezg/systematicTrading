# -*- coding: utf-8 -*-
"""Building a Survivorship Bias-Free Cryptocurrency Dataset - [Full Version]

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oc_53xSSLb0x2U6hQl8Anvo8SXkjaXqO

# **CryptoDB: Building a Survivorship Bias-Free Cryptocurrency Dataset - [Full Version]**

**Author:**  
[**Mohamed Gabriel**](https://www.linkedin.com/in/msmgabriel/)  
*Software Engineer at Concretum Group*

This notebook provides a **comprehensive pipeline** for fetching, processing, and analyzing the **complete cryptocurrency market data** from the CoinMarketCap API. The focus is on including **both active and inactive (delisted or failed)** coins to avoid **survivorship bias**, which is a common issue in many crypto backtesting workflows.

Originally, this code was written by [**Dr. Andrea Barbon**](https://www.linkedin.com/in/andrea-barbon-89665631/) for the research paper [**"Catching Crypto Trends: A Tactical Approach for Bitcoin and Altcoins"**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5209907).

> ⚠️ **Warning**: This notebook builds the **full cryptocurrency market dataset** with ~23,286 cryptocurrencies and ~28.6 million daily observations. The complete process takes **approximately 22+ hours** to run.
>
> For a lighter introduction, see the [10-sample version](https://colab.research.google.com/drive/1hYjVDR6G6Ndw-JagarFCdpzDD-q-kcY8?usp=sharing).

Feel free to use, adapt, and extend this code for your own research, trading systems, or academic projects.

## 1. Setup and Imports
"""

import pandas as pd
import numpy as np
import os
import requests
from tqdm import tqdm as tq
from datetime import datetime as dt
from pandas.tseries.offsets import *
from glob import glob as g
import matplotlib.pyplot as plt

from requests import Request, Session
from requests.exceptions import ConnectionError, Timeout, TooManyRedirects
import json
import time

"""## 2. API Configuration

"""

# CoinMarketCap API Key
KEY = '179c21ec-d0b1-472c-9443-4a8b371e2629'

# Configure API headers
headers = {
  'Accepts': 'application/json',
  'X-CMC_PRO_API_KEY': KEY,
}

# Base URL for the API
base_url = "https://pro-api.coinmarketcap.com/"

"""## 3. Data Collection Functions

"""

def get_daily_OHLCV(the_id):
    """
    Fetch daily OHLCV (Open, High, Low, Close, Volume) data for a cryptocurrency

    Parameters:
    the_id (int): CoinMarketCap ID of the cryptocurrency

    Returns:
    DataFrame: OHLCV data for the specified cryptocurrency
    """
    time.sleep(0.7)  # We have a limit of 90 calls per minute
    os.makedirs("crypto", exist_ok=True)
    url = base_url + 'v2/cryptocurrency/ohlcv/historical'
    parameters = {
        'id': the_id,
        'time_period': 'daily',
        'time_start': '2010-1-1',
        'time_end': '2025-10-13'
    }

    session = Session()
    session.headers.update(headers)

    try:
        response = session.get(url, params=parameters)
        response.raise_for_status()  # raises HTTPError for bad responses
        data = json.loads(response.text)
        te = pd.DataFrame(
            [data['data']['quotes'][x]['quote']['USD'] for x in range(len(data['data']['quotes']))]
        )
        te['id'] = data['data']['id']
        te['symbol'] = data['data']['symbol']
        te['ts'] = pd.to_datetime(te['timestamp'].str[:10])
        te = te[['id', 'symbol', 'ts', *te.columns[:6]]]
        return te
    except Exception as e:
        print(e)
         # Log errors to file
        log_path = os.path.join("crypto", "errors.log")
        with open(log_path, "a") as f:
            f.write(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Error fetching ID {the_id}: {e}\n")
        print(f"Error fetching ID {the_id}: {e}")
        return None
    

"""### 3.1 Metadata Collection Function

"""

# Define relevant tags for metadata filtering
relevant_tags = [
    'wrapped', 'stablecoin', 'collectibles-nfts', 'memes', 'iot', 'dao',
    'governance', 'mineable', 'pow', 'pos', 'sha-256', 'store-of-value',
    'medium-of-exchange', 'scrypt', 'layer-1', 'layer-2',
]

# Columns to extract from metadata
cols = ['id', 'name', 'symbol', 'category', 'tags']

def get_metadata(the_ids):
    """
    Fetch metadata for a list of cryptocurrency IDs

    Parameters:
    the_ids (list): List of CoinMarketCap IDs

    Returns:
    DataFrame: Metadata for the specified cryptocurrencies
    """
    time.sleep(0.01)  # We have a limit of 90 calls per minute
    url = base_url + 'v2/cryptocurrency/info'
    parameters = {'id': ",".join([str(x) for x in the_ids]), 'skip_invalid': 'true'}
    session = Session()
    session.headers.update(headers)

    try:
        response = session.get(url, params=parameters)
        data = json.loads(response.text)['data']
        the_ids = [x for x in data.keys() if int(x) in the_ids]
        te = pd.DataFrame([data[str(x)] for x in the_ids])[cols]
        te = te.fillna("[0]")
        for tag in relevant_tags:
            te[tag] = te['tags'].apply(lambda x: tag in x)

        return te.drop('tags', axis=1)
    except Exception as e:
        print(e)
        return None

"""## 4. Data Collection Process

### 4.1 Collect OHLCV Data for Cryptocurrencies
"""
# We use this loop to gather data for ids from 1 to 40,000
""" M = 1_000

for N in range(1, 40 + 1):
    ids = range(M*(N-1)+1, M*N+1)

    res = []
    for the_id in tq(ids):
        df = get_daily_OHLCV(the_id)
        if df is None or df.empty:
            continue
        res.append(df)

    if res:
        res = pd.concat(res)
        res.to_parquet(f"crypto/OHLCV_{N}.par") """
        

"""### 4.2 Collect Metadata for Cryptocurrencies

"""

files = g("crypto/OHLCV*.par")
print(f"{len(files)} files")
dfs = []
for file in files:
    df = pd.read_parquet(file)
    dfs.append(df)
df = pd.concat(dfs)

# Add statistics for each cryptocurrency
df['stat'] = df.groupby(['id'])['ts'].transform('min')
df['end'] = df.groupby(['id'])['ts'].transform('max')
df['days'] = df.groupby(['id'])['ts'].transform('size')

print("{0:0,.0f} cryptos".format(df['id'].nunique()))
print("{0:0,.0f} observations".format(len(df)))

# Collect metadata for all cryptocurrencies
res = []
ids = df.groupby(['id']).first().sort_index().index
M = 100
N = int(max(ids) / M) + 1

i = 1
for the_id in tq(range(1, N+1)):
    if i % 90 == 0:
        time.sleep(80)  # Respect API rate limits
    res.append(get_metadata(range((i-1)*M, (i)*M)))
    i += 1

res = pd.concat(res)
assert df['id'].nunique() <= res['id'].nunique()

"""### 4.3 Combine OHLCV Data with Metadata

"""

# Attach metadata to OHLCV data
ds = df.set_index(['id']).copy()
ds[res.set_index(['id']).columns] = res.set_index(['id'])
ds = ds.sort_values(['id', 'ts'])

# Save the combined data
res.to_parquet("crypto/metadata.par")
ds.to_parquet("crypto/OHLCV_with_metadata.par")

# Save the full OHLCV dataset
df.to_parquet("crypto/full_OHLCV.par")

"""## 5. Data Analysisqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq111111111111

### 5.1 Load and Summarize Data
"""

# Load the previously saved data
ds = pd.read_parquet("crypto/OHLCV_with_metadata.par")

# Check available categories
print("Available categories:")
print(ds['category'].unique())

# Count unique cryptocurrencies and total observations
print("{0:0,.0f} cryptos".format(ds['symbol'].nunique()))
print("{0:0,.0f} observations".format(len(ds)))

# Create a summary dataframe with key metrics
summary = ds.reset_index().groupby(['id']).agg({
    'symbol': 'first',
    'volume': 'sum',
    'market_cap': 'last',
    'close': 'last'
}).sort_values('market_cap', ascending=False)

# Display top 50 cryptocurrencies by market cap
summary.head(50)

"""### 5.2 Visualize Price Data for Selected Cryptocurrencies

"""

# Plot price history for a selected cryptocurrency
# Change the_id to visualize different cryptocurrencies:
# 1 = Bitcoin (BTC)
# 2 = Litecoin (LTC)
# 1027 = Ethereum (ETH)

the_id = 36507  # BTC

fig, ax1 = plt.subplots(1, 1, figsize=(12, 6))
te = ds.reset_index()
te = te[te['id'] == the_id].set_index(['ts'])
te['close'].plot()
fig.suptitle(f"Price History for {te['symbol'].iloc[0]}")
ax1.grid()
plt.show()